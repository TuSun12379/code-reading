{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOO(object):\n",
    "    \n",
    "    def bar(self, message):\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello world!\n"
    }
   ],
   "source": [
    "FOO1 = FOO().bar(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooParent:\n",
    "    def bar(self, message):\n",
    "        print(message)\n",
    "\n",
    "class Foochild(FooParent):\n",
    "    def bar(self, message):\n",
    "        FooParent.bar(self, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello world again!\n"
    }
   ],
   "source": [
    "Foochild().bar(\"Hello world again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FooParent2: # use super\n",
    "    def bar(self, message):\n",
    "        print(message)\n",
    "\n",
    "class Foochild2(FooParent2):\n",
    "    def bar(self, message):\n",
    "        super(Foochild2, self).bar(message) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello world three!\n"
    }
   ],
   "source": [
    "Foochild2().bar(\"Hello world three!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperspy.signals import Signal2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_wrap__',\n '__call__',\n '__class__',\n '__deepcopy__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__divmod__',\n '__doc__',\n '__eq__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__init__',\n '__init_subclass__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__lshift__',\n '__lt__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__next__',\n '__or__',\n '__pos__',\n '__pow__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__rshift__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_additional_slicing_targets',\n '_alias_signal_types',\n '_apply_function_on_data_and_remove_axis',\n '_assign_subclass',\n '_auto_reverse_bss_component',\n '_binary_operator_ruler',\n '_calculate_recmatrix',\n '_calculate_summary_statistics',\n '_check_signal_dimension_equals_one',\n '_check_signal_dimension_equals_two',\n '_create_metadata',\n '_cycle_signal',\n '_data_aligned_with_axes',\n '_deepcopy_with_new_data',\n '_dtype',\n '_estimate_elbow_position',\n '_estimate_poissonian_noise_variance',\n '_export_factors',\n '_export_loadings',\n '_get_array_slices',\n '_get_factors',\n '_get_loadings',\n '_get_navigation_signal',\n '_get_plot_title',\n '_get_signal_signal',\n '_get_undefined_axes_list',\n '_iterate_signal',\n '_lazy',\n '_load_dictionary',\n '_ma_workaround',\n '_make_sure_data_is_contiguous',\n '_map_all',\n '_map_iterate',\n '_plot_factors_or_pchars',\n '_plot_loadings',\n '_plot_permanent_markers',\n '_print_summary',\n '_remove_axis',\n '_render_figure',\n '_replot',\n '_signal_dimension',\n '_signal_type',\n '_slicer',\n '_summary',\n '_to_dictionary',\n '_unary_operator_ruler',\n '_unfold',\n '_unmix_components',\n '_validate_rebin_args_and_get_factors',\n 'add_gaussian_noise',\n 'add_marker',\n 'add_poissonian_noise',\n 'add_ramp',\n 'align2D',\n 'apply_apodization',\n 'as_lazy',\n 'as_signal1D',\n 'as_signal2D',\n 'blind_source_separation',\n 'change_dtype',\n 'copy',\n 'create_model',\n 'crop',\n 'crop_image',\n 'data',\n 'decomposition',\n 'deepcopy',\n 'derivative',\n 'diff',\n 'estimate_poissonian_noise_variance',\n 'estimate_shift2D',\n 'export_bss_results',\n 'export_decomposition_results',\n 'fft',\n 'fold',\n 'get_bss_factors',\n 'get_bss_loadings',\n 'get_bss_model',\n 'get_current_signal',\n 'get_decomposition_factors',\n 'get_decomposition_loadings',\n 'get_decomposition_model',\n 'get_dimensions_from_data',\n 'get_explained_variance_ratio',\n 'get_histogram',\n 'ifft',\n 'indexmax',\n 'indexmin',\n 'integrate1D',\n 'integrate_simpson',\n 'is_rgb',\n 'is_rgba',\n 'is_rgbx',\n 'map',\n 'max',\n 'mean',\n 'min',\n 'nanmax',\n 'nanmean',\n 'nanmin',\n 'nanstd',\n 'nansum',\n 'nanvar',\n 'normalize_bss_components',\n 'normalize_decomposition_components',\n 'normalize_poissonian_noise',\n 'plot',\n 'plot_bss_factors',\n 'plot_bss_loadings',\n 'plot_bss_results',\n 'plot_cumulative_explained_variance_ratio',\n 'plot_decomposition_factors',\n 'plot_decomposition_loadings',\n 'plot_decomposition_results',\n 'plot_explained_variance_ratio',\n 'print_summary_statistics',\n 'rebin',\n 'reverse_bss_component',\n 'reverse_decomposition_component',\n 'rollaxis',\n 'save',\n 'set_signal_origin',\n 'set_signal_type',\n 'split',\n 'squeeze',\n 'std',\n 'sum',\n 'swap_axes',\n 'to_signal1D',\n 'transpose',\n 'undo_treatments',\n 'unfold',\n 'unfold_navigation_space',\n 'unfold_signal_space',\n 'unfolded',\n 'update_plot',\n 'valuemax',\n 'valuemin',\n 'var']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "dir(Signal2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "\n",
    "f = h5py.File(\"h1.hdf5\", \"w\") # 创建一个空的hdf5文件。\n",
    "\n",
    "d1 = f.create_dataset(\"dset1\", (20, ), \"i\")　# 创建数据集，参数分别为数据集的名称，shape和元素类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dset1\n/dset1\n(20,)\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
    }
   ],
   "source": [
    "for key in f.keys():\n",
    "    print(key)\n",
    "    print(f[key].name)\n",
    "    print(f[key].shape)\n",
    "    print(f[key].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dset1\n/dset1\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\ndset2\n/dset2\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "d1[...] = np.arange(20)  # assign value for dataset1\n",
    "\n",
    "f[\"dset2\"] = np.arange(15) # create another dataset and assign value\n",
    "\n",
    "for key in f.keys(): # loop the dataset in f\n",
    "    print(key)\n",
    "    print(f[key].name)\n",
    "    print(f[key].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data3\n/data3\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\ndset1\n/dset1\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\ndset2\n/dset2\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n"
    }
   ],
   "source": [
    "a = np.arange(18)\n",
    "f[\"data3\"] = a \n",
    "def print_f(f):  # creat a fuction to do the stupid things\n",
    "    for key in f.keys():\n",
    "        print(key)\n",
    "        print(f[key].name)\n",
    "        print(f[key].value)\n",
    "\n",
    "print_f(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = h5py.File(\"processed_all.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = f.create_group(\"bar\") # create a group\n",
    "g1[\"dset1\"] = np.arange(10) # put three different datset\n",
    "g1[\"dset2\"] = np.arange(15)\n",
    "g1[\"dset3\"] = np.arange(20).reshape((4, 5))\n",
    "\n",
    "def print_g(g): # create a stupid func to do the stupid things\n",
    "    for key in g.keys():\n",
    "        print(g)\n",
    "        print(g[key].name)\n",
    "        print(g[key].value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<HDF5 group \"/bar\" (3 members)>\n/bar/dset1\n[0 1 2 3 4 5 6 7 8 9]\n<HDF5 group \"/bar\" (3 members)>\n/bar/dset2\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n<HDF5 group \"/bar\" (3 members)>\n/bar/dset3\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]]\n"
    }
   ],
   "source": [
    "print_g(g1) # show the group members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Experiments\n"
    }
   ],
   "source": [
    "for group in f2: # show the group in f2\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Experiments\n<class 'str'>\n"
    }
   ],
   "source": [
    "for group in f2: # show the group in f2\n",
    "    print(group)\n",
    "    print(type(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<KeysViewHDF5 ['Experiments']>\n"
    }
   ],
   "source": [
    "print(f2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Experiments\n"
    }
   ],
   "source": [
    "for group in f2: # show the group in f2\n",
    "    print(group)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Experiments\nExperiments/serialED\nExperiments/serialED/axis-0\nExperiments/serialED/axis-1\nExperiments/serialED/axis-2\nExperiments/serialED/data\nExperiments/serialED/learning_results\nExperiments/serialED/metadata\nExperiments/serialED/metadata/General\nExperiments/serialED/metadata/Processing\nExperiments/serialED/metadata/Processing/apply_stretch_correction\nExperiments/serialED/metadata/Processing/datfiles\nExperiments/serialED/metadata/Processing/find_peaks_and_clean_images\nExperiments/serialED/metadata/Processing/get_direct_beam_position\nExperiments/serialED/metadata/Processing/remove_background\nExperiments/serialED/metadata/Signal\nExperiments/serialED/metadata/_HyperSpy\nExperiments/serialED/metadata/_HyperSpy/Folding\nExperiments/serialED/original_metadata\n"
    }
   ],
   "source": [
    "def prtname(name): # read the files in the hdf5 file\n",
    "    print(name)\n",
    "\n",
    "f2.visit(prtname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}